}
#keep the 4 spectra per individual plant that are closest to the mean
keep = function(spectra){
a = dist.rank(spectra)
x1 = subset(spectra, a < 5)
}
#split the spectra objects to individual plants, apply above funtions, and
#recombine them.
trim.spectra = function(spectra){
spec.list = lapply(split(spectra, meta(spectra)$Name), keep)
clean_spec = Reduce(combine, spec.list)
return(clean_spec)
}
################################################################################
#Primary functions
################################################################################
#This function adds the metadata, cuts spectra to wavelength 400:2400, removes
#reflectance values greater than 1, reduces the data to the 4 measurements
#that are closest to the mean for each individual and smooths the spectra.
thebigclean <- function(spectra_path, metadata_path){
meta.spectra = add_meta(spectra_path, metadata_path)
spectra_cut = meta.spectra[, 400:2400]
spec1 = spectra_cut[!rowSums(spectra_cut > 1),]
spec2 = trim.spectra(spec1)
spec3 = spec2[!meta(spec2)$Notes == "not sequenced",]
spec4 = spec3[!meta(spec3)$Clone == "Yes",]
clean_spectra = smooth(spec4)
return(clean_spectra)
}
################################################################################
#Set working directory to folder containing downloaded spectral data
################################################################################
setwd("C:/Users/istas/OneDrive/Documents/Dryas Research/Dryas 2.0")
tm_path = "Scans_raw/Dry Scans/Twelve_Mile/12mile-dryas-08082019"
tm_meta = "Scans_raw/Dry Scans/Twelve_Mile/tm_pops.csv"
tm_clean = thebigclean(tm_path, tm_meta)
tm_vn = normalize(tm_clean)
meta(tm_clean)
head(meta(tm_clean))
bg_path = "Scans_raw/Dry Scans/Bison_Gulch/bisonGulch_dry"
bg_meta = "Scans_raw/Dry Scans/Bison_Gulch/bg_pops.csv"
bg_clean = thebigclean(bg_path, bg_meta)
bg_vn = normalize(bg_clean)
################################################################################
#Eagle Summit
################################################################################
es_path = "Scans_raw/Dry Scans/Eagle_Summit/es-dry"
es_meta = "Scans_raw/Dry Scans/Eagle_Summit/es_pops.csv"
es_clean = thebigclean(es_path, es_meta)
es_vn = normalize(es_clean)
################################################################################
#Murphy Dome B
################################################################################
mdb_path = "Scans_raw/Dry Scans/Murphy_Dome_B/murphyB-dry"
mdb_meta = "Scans_raw/Dry Scans/Murphy_Dome_B/mdb_pops.csv"
mdb_clean = thebigclean(mdb_path, mdb_meta)
mdb_vn = normalize(mdb_clean)
################################################################################
#Wickersham Dome A
################################################################################
wda_path = "Scans_raw/Dry Scans/Wickersham_A/wickershamdome-dry"
wda_meta = "Scans_raw/Dry Scans/Wickersham_A/wda_pops.csv"
wda_clean = thebigclean(wda_path, wda_meta)
wda_vn = normalize(wda_clean)
################################################################################
#Wickersham Dome B
################################################################################
wdb_path = "Scans_raw/Dry Scans/Wickersham_B/wdb-dry"
wdb_meta = "Scans_raw/Dry Scans/Wickersham_B/wdb_pops.csv"
wdb_clean = thebigclean(wdb_path, wdb_meta)
wdb_vn = normalize(wdb_clean)
################################################################################
#combine
################################################################################
clean_big3 = Reduce(combine, list(tm_clean, es_clean, wdb_clean))
vn_big3 = normalize(clean_big3)
clean_all = Reduce(combine, list(tm_clean, es_clean, wdb_clean, mdb_clean,
wda_clean, bg_clean))
all_vn = normalize(clean_all)
################################################################################
#separate by three primary sites
################################################################################
meta3 = meta(clean_big3)
ala3 = clean_big3[meta3$Species == "alaskensis"]
oct3 = clean_big3[meta3$Species == "octopetala"]
big3.no_hybrids = combine(ala3, oct3)
vn_big3.no_hybrids = normalize(big3.no_hybrids)
################################################################################
#Save Data
################################################################################
#Save Cleaned Spectra
saveRDS(tm_clean, "Clean-up/Clean_spectra/tm_clean.rds")
saveRDS(bg_clean, "Clean-up/Clean_spectra/bg_clean.rds")
saveRDS(es_clean, "Clean-up/Clean_spectra/es_clean.rds")
saveRDS(mdb_clean, "Clean-up/Clean_spectra/mdb_clean.rds")
saveRDS(wda_clean, "Clean-up/Clean_spectra/wda_clean.rds")
saveRDS(wdb_clean, "Clean-up/Clean_spectra/wdb_clean.rds")
saveRDS(clean_all, "Clean-up/Clean_spectra/clean_all.rds")
saveRDS(clean_big3, "Clean-up/Clean_spectra/clean_big3.rds")
saveRDS(big3.no_hybrids, "Clean-up/Clean_spectra/big3.no_hybrids.rds")
#Save Vector Normalized Spectra
saveRDS(tm_vn, "Clean-up/Vector_normalized/tm_vn.rds")
saveRDS(bg_vn, "Clean-up/Vector_normalized/bg_vn.rds")
saveRDS(es_vn, "Clean-up/Vector_normalized/es_vn.rds")
saveRDS(mdb_vn, "Clean-up/Vector_normalized/mdb_vn.rds")
saveRDS(wda_vn, "Clean-up/Vector_normalized/wda_vn.rds")
saveRDS(wdb_vn, "Clean-up/Vector_normalized/wdb_vn.rds")
saveRDS(all_vn, "Clean-up/Vector_normalized/all_vn.rds")
saveRDS(vn_big3, "Clean-up/Vector_normalized/vn_big3.rds")
saveRDS(vn_big3.no_hybrids, "Clean-up/Vector_normalized/vn_big3.no_hybrids.rds")
#add metadata to raw spectra
add_meta <- function(spectra_path, metadata_path){
spectra_raw = read_spectra(path = spectra_path, format = "sed")
metadata = read.csv(file = metadata_path, header = TRUE, stringsAsFactors = FALSE)
meta(spectra_raw) <- metadata
return(spectra_raw)
}
#The goal of the following functions is to keep the 4 spectral measurements that
#are closest to the mean reflectance values for each individual plant. The
#sample design involved stacking leaves 3 times and taking 2 reflectance
#measurements per stack interval. Therefore, the first stack tended to have much
#of the black background showing, and the third stack probably had more light
#reflected from the leaves than observed in nature (think about how stacking a
#leaf would simulate scanning a thicker leaf). The idea here is that restricting
#measurements to the 3 closest to the mean should provide more data to work with
#compared to just taking the mean while also removing high and low reflectance
#measurements caused by sample design.
#subtract the mean reflectance from measured reflectance (i.e. calculate
#distance from the mean)
center_scale = function(spectra){
scale(spectra, scale = FALSE)
}
#rank spectra by distance from the mean
dist.rank = function(spectra){
rank(rowSums(abs(center_scale(spectra))))
}
#keep the 4 spectra per individual plant that are closest to the mean
keep = function(spectra){
a = dist.rank(spectra)
x1 = subset(spectra, a < 5)
}
#split the spectra objects to individual plants, apply above funtions, and
#recombine them.
trim.spectra = function(spectra){
spec.list = lapply(split(spectra, meta(spectra)$Name), keep)
clean_spec = Reduce(combine, spec.list)
return(clean_spec)
}
################################################################################
#Primary functions
################################################################################
#This function adds the metadata, cuts spectra to wavelength 400:2400, removes
#reflectance values greater than 1, reduces the data to the 4 measurements
#that are closest to the mean for each individual and smooths the spectra.
thebigclean <- function(spectra_path, metadata_path){
meta.spectra = add_meta(spectra_path, metadata_path)
spectra_cut = meta.spectra[, 400:2400]
spec1 = spectra_cut[!rowSums(spectra_cut > 1),]
spec2 = trim.spectra(spec1)
clean_spectra = smooth(spec2)
return(clean_spectra)
}
################################################################################
#Set working directory to folder containing downloaded spectral data
################################################################################
setwd("C:/Users/istas/OneDrive/Documents/Dryas Research/Dryas 2.0")
################################################################################
#Twelve Mile
################################################################################
tm_path = "Scans_raw/Dry Scans/Twelve_Mile/12mile-dryas-08082019"
tm_meta = "Scans_raw/Dry Scans/Twelve_Mile/tm_pops.csv"
tm_clean1 = thebigclean(tm_path, tm_meta)
tm_clean = tm_clean1[!meta(tm_clean1)$Clone == "Yes",]
tm_vn = normalize(tm_clean)
################################################################################
#Bison Gulch
################################################################################
bg_path = "Scans_raw/Dry Scans/Bison_Gulch/bisonGulch_dry"
bg_meta = "Scans_raw/Dry Scans/Bison_Gulch/bg_pops.csv"
bg_clean = thebigclean(bg_path, bg_meta)
bg_vn = normalize(bg_clean)
################################################################################
#Eagle Summit
################################################################################
es_path = "Scans_raw/Dry Scans/Eagle_Summit/es-dry"
es_meta = "Scans_raw/Dry Scans/Eagle_Summit/es_pops.csv"
es_clean1 = thebigclean(es_path, es_meta)
es_clean2 = es_clean1[!meta(es_clean1)$Clone == "Yes",]
es_clean = es_clean2[!meta(es_clean2)$Notes == "not sequenced",]
es_vn = normalize(es_clean)
################################################################################
#Murphy Dome B
################################################################################
mdb_path = "Scans_raw/Dry Scans/Murphy_Dome_B/murphyB-dry"
mdb_meta = "Scans_raw/Dry Scans/Murphy_Dome_B/mdb_pops.csv"
mdb_clean = thebigclean(mdb_path, mdb_meta)
mdb_vn = normalize(mdb_clean)
################################################################################
#Wickersham Dome A
################################################################################
wda_path = "Scans_raw/Dry Scans/Wickersham_A/wickershamdome-dry"
wda_meta = "Scans_raw/Dry Scans/Wickersham_A/wda_pops.csv"
wda_clean = thebigclean(wda_path, wda_meta)
wda_vn = normalize(wda_clean)
################################################################################
#Wickersham Dome B
################################################################################
wdb_path = "Scans_raw/Dry Scans/Wickersham_B/wdb-dry"
wdb_meta = "Scans_raw/Dry Scans/Wickersham_B/wdb_pops.csv"
wdb_clean1 = thebigclean(wdb_path, wdb_meta)
wdb_clean2 = wdb_clean1[!meta(wdb_clean1)$Clone == "Yes",]
wdb_clean = wdb_clean2[!meta(wdb_clean2)$Notes == "not sequenced",]
wdb_vn = normalize(wdb_clean)
wdb_path = "Scans_raw/Dry Scans/Wickersham_B/wdb-dry"
wdb_meta = "Scans_raw/Dry Scans/Wickersham_B/wdb_pops.csv"
wdb_clean = thebigclean(wdb_path, wdb_meta)
wdb_vn = normalize(wdb_clean)
clean_big3 = Reduce(combine, list(tm_clean, es_clean, wdb_clean))
vn_big3 = normalize(clean_big3)
clean_all = Reduce(combine, list(tm_clean, es_clean, wdb_clean, mdb_clean,
wda_clean, bg_clean))
all_vn = normalize(clean_all)
################################################################################
#separate by three primary sites
################################################################################
meta3 = meta(clean_big3)
ala3 = clean_big3[meta3$Species == "alaskensis"]
oct3 = clean_big3[meta3$Species == "octopetala"]
big3.no_hybrids = combine(ala3, oct3)
vn_big3.no_hybrids = normalize(big3.no_hybrids)
################################################################################
#Save Data
################################################################################
#Save Cleaned Spectra
saveRDS(tm_clean, "Clean-up/Clean_spectra/tm_clean.rds")
saveRDS(bg_clean, "Clean-up/Clean_spectra/bg_clean.rds")
saveRDS(es_clean, "Clean-up/Clean_spectra/es_clean.rds")
saveRDS(mdb_clean, "Clean-up/Clean_spectra/mdb_clean.rds")
saveRDS(wda_clean, "Clean-up/Clean_spectra/wda_clean.rds")
saveRDS(wdb_clean, "Clean-up/Clean_spectra/wdb_clean.rds")
saveRDS(clean_all, "Clean-up/Clean_spectra/clean_all.rds")
saveRDS(clean_big3, "Clean-up/Clean_spectra/clean_big3.rds")
saveRDS(big3.no_hybrids, "Clean-up/Clean_spectra/big3.no_hybrids.rds")
#Save Vector Normalized Spectra
saveRDS(tm_vn, "Clean-up/Vector_normalized/tm_vn.rds")
saveRDS(bg_vn, "Clean-up/Vector_normalized/bg_vn.rds")
saveRDS(es_vn, "Clean-up/Vector_normalized/es_vn.rds")
saveRDS(mdb_vn, "Clean-up/Vector_normalized/mdb_vn.rds")
saveRDS(wda_vn, "Clean-up/Vector_normalized/wda_vn.rds")
saveRDS(wdb_vn, "Clean-up/Vector_normalized/wdb_vn.rds")
saveRDS(all_vn, "Clean-up/Vector_normalized/all_vn.rds")
saveRDS(vn_big3, "Clean-up/Vector_normalized/vn_big3.rds")
saveRDS(vn_big3.no_hybrids, "Clean-up/Vector_normalized/vn_big3.no_hybrids.rds")
es_w_path = "Scans_raw/Wet Scans/es_wet"
es_w_meta = "Scans_raw/Wet Scans/es_wet/es_pops_wet.csv"
es_w_clean1 = thebigclean(es_w_path, es_w_meta)
es_w_clean2 = es_W_clean1[!meta(es_W_clean1)$Clone == "Yes",]
es_w_clean = es_W_clean2[!meta(es_w_clean2)$Notes == "not sequenced",]
vn_es_w = normalize(es_w_clean)
es_w_clean1 = thebigclean(es_w_path, es_w_meta)
#add metadata to raw spectra
add_meta <- function(spectra_path, metadata_path){
spectra_raw = read_spectra(path = spectra_path, format = "sed")
metadata = read.csv(file = metadata_path, header = TRUE, stringsAsFactors = FALSE)
meta(spectra_raw) <- metadata
return(spectra_raw)
}
#The goal of the following functions is to keep the 4 spectral measurements that
#are closest to the mean reflectance values for each individual plant. The
#sample design involved stacking leaves 3 times and taking 2 reflectance
#measurements per stack interval. Therefore, the first stack tended to have much
#of the black background showing, and the third stack probably had more light
#reflected from the leaves than observed in nature (think about how stacking a
#leaf would simulate scanning a thicker leaf). The idea here is that restricting
#measurements to the 3 closest to the mean should provide more data to work with
#compared to just taking the mean while also removing high and low reflectance
#measurements caused by sample design.
#subtract the mean reflectance from measured reflectance (i.e. calculate
#distance from the mean)
center_scale = function(spectra){
scale(spectra, scale = FALSE)
}
#rank spectra by distance from the mean
dist.rank = function(spectra){
rank(rowSums(abs(center_scale(spectra))))
}
#keep the 4 spectra per individual plant that are closest to the mean
keep = function(spectra){
a = dist.rank(spectra)
x1 = subset(spectra, a < 5)
}
#split the spectra objects to individual plants, apply above funtions, and
#recombine them.
trim.spectra = function(spectra){
spec.list = lapply(split(spectra, meta(spectra)$Name), keep)
clean_spec = Reduce(combine, spec.list)
return(clean_spec)
}
################################################################################
#Primary functions
################################################################################
#This function adds the metadata, cuts spectra to wavelength 400:2400, removes
#reflectance values greater than 1, reduces the data to the 4 measurements
#that are closest to the mean for each individual and smooths the spectra.
thebigclean <- function(spectra_path, metadata_path){
meta.spectra = add_meta(spectra_path, metadata_path)
spectra_cut = meta.spectra[, 400:2400]
spec1 = spectra_cut[!rowSums(spectra_cut > 1),]
spec2 = trim.spectra(spec1)
clean_spectra = smooth(spec2)
return(clean_spectra)
}
################################################################################
#Set working directory to folder containing downloaded spectral data
################################################################################
setwd("C:/Users/istas/OneDrive/Documents/Dryas Research/Dryas 2.0")
es_w_path = "Scans_raw/Wet Scans/es_wet"
es_w_meta = "Scans_raw/Wet Scans/es_wet/es_pops_wet.csv"
es_w_clean1 = thebigclean(es_w_path, es_w_meta)
es_w_clean2 = es_W_clean1[!meta(es_w_clean1)$Clone == "Yes",]
es_w_clean2 = es_w_clean1[!meta(es_w_clean1)$Clone == "Yes",]
es_w_clean = es_w_clean2[!meta(es_w_clean2)$Notes == "not sequenced",]
vn_es_w = normalize(es_w_clean)
wda_w_path = "Scans_raw/Wet Scans/wda_wet"
wda_w_meta = "Scans_raw/Wet Scans/wda_wet/wda_pops_wet.csv"
wda_w_clean = thebigclean(wda_w_path, wda_w_meta)
vn_wda_w = normalize(wda_w_clean)
#Wickerhamd Dome B
wdb_w_path = "Scans_raw/Wet Scans/wdb_wet"
wdb_w_meta = "Scans_raw/Wet Scans/wdb_wet/wdb_pops_wet.csv"
wdb_w_clean = thebigclean(wdb_w_path, wdb_w_meta)
vn_wdb_w = normalize(wdb_w_clean)
#all wet
Clean_all_w = Reduce(combine, list(wdb_w_clean, wda_w_clean, es_w_clean))
vn_all_w = normalize(Clean_all_w)
saveRDS(Clean_all_w, "Clean-up/Clean_spectra/clean_all_w.rds")
saveRDS(vn_all_w, "Clean-up/Vector_normalized/vn_all_w.rds")
head(meta(Clean_all_w))
library(mixOmics)
library(spectrolab)
library(plotrix)
################################################################################
#Set working directory to folder containing downloaded rds files
################################################################################
setwd("C:/Users/istas/OneDrive/Documents/Dryas Research/Dryas 2.0")
################################################################################
# Fit PLS_DA model all
################################################################################
#data
spec_all = readRDS("Clean-up/Vector_normalized/vn_all.rds")
################################################################################
# Fit PLS_DA model all
################################################################################
#data
spec_all = readRDS("Clean-up/Vector_normalized/all_vn.rds")
meta(spec_all)
?perf
spec_all = readRDS("Clean-up/Vector_normalized/all_vn.rds")
names(spec_all) = meta(spec_all)$GenePop_ID
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
spec_mat = spec_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
#determine number of components to use
plsda.fit = plsda(spec_mat, resp, ncomp = 40)
perf.plsda = perf(plsda.fit, validation = "Mfold", folds = 5,
progressBar = TRUE, auc = TRUE, nrepeat = 40)
plot(perf.plsda, col = color.mixo(1:3), sd = TRUE,
legend.position = "horizontal")
perf.plsda
set.seed(25)
samp <- sample(1:3, nrow(spec_mat), replace = TRUE)
# 1/3 of the data will compose the test set
test <- which(samp == 1)
# rest will compose the training set
train <- setdiff(1:nrow(spec_mat), test)
## For PLS-DA, train the model
plsda.train <- plsda(spec_mat[train, ], resp[train], ncomp = 25)
# then predict
test.predict <- predict(plsda.train, spec_mat[test, ], dist = "max.dist")
# store prediction for the 4th component
prediction <- test.predict$class$max.dist[,25]
# calculate the error rate of the model
confusion.mat = get.confusion_matrix(truth = resp[test], predicted = prediction)
cm1 = as.data.frame(confusion.mat)
get.BER(confusion.mat)
#plot
par(mar = c(2, 4, 3, 4), oma = c(2, 4, 3, 2))
color2D.matplot(cm1,
show.values = TRUE,
axes = FALSE,
xlab = "",
ylab = "",
vcex = 2,
vcol = "black",
extremes = c("white", "deepskyblue3"))
axis(3, at = seq_len(ncol(cm1)) - 0.5,
labels = names(cm1), tick = FALSE, cex.axis = 1)
axis(2, at = seq_len(nrow(cm1)) -0.5,
labels = rev(rownames(cm1)), tick = FALSE, las = 1, cex.axis = 1)
meta = meta(spec_all)
View(meta)
unique(meta$GenePop_ID)
spec_all = spec_all1[!meta(spec_all1)$GenePop_ID == "NaN",]
spec_all1 = readRDS("Clean-up/Vector_normalized/all_vn.rds")
spec_all = spec_all1[!meta(spec_all1)$GenePop_ID == "NaN",]
unique(meta(spec_all1)$GenePop_ID)
unique(meta(spec_all)$GenePop_ID)
#data
spec_all1 = readRDS("Clean-up/Vector_normalized/all_vn.rds")
spec_all = spec_all1[!meta(spec_all1)$GenePop_ID == "NaN",]
names(spec_all) = meta(spec_all)$GenePop_ID
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
spec_mat = spec_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
#determine number of components to use
plsda.fit = plsda(spec_mat, resp, ncomp = 30)
perf.plsda = perf(plsda.fit, validation = "Mfold", folds = 5,
progressBar = TRUE, auc = TRUE, nrepeat = 50)
plot(perf.plsda, col = color.mixo(1:3), sd = TRUE,
legend.position = "horizontal")
#Run PLSDA
set.seed(25)
samp <- sample(1:3, nrow(spec_mat), replace = TRUE)
# 1/3 of the data will compose the test set
test <- which(samp == 1)
# rest will compose the training set
train <- setdiff(1:nrow(spec_mat), test)
## For PLS-DA, train the model
plsda.train <- plsda(spec_mat[train, ], resp[train], ncomp = 23)
# then predict
test.predict <- predict(plsda.train, spec_mat[test, ], dist = "max.dist")
# store prediction for the 4th component
prediction <- test.predict$class$max.dist[,23]
# calculate the error rate of the model
confusion.mat = get.confusion_matrix(truth = resp[test], predicted = prediction)
cm1 = as.data.frame(confusion.mat)
get.BER(confusion.mat)
#plot
par(mar = c(2, 4, 3, 4), oma = c(2, 4, 3, 2))
color2D.matplot(cm1,
show.values = TRUE,
axes = FALSE,
xlab = "",
ylab = "",
vcex = 2,
vcol = "black",
extremes = c("white", "deepskyblue3"))
axis(3, at = seq_len(ncol(cm1)) - 0.5,
labels = names(cm1), tick = FALSE, cex.axis = 1)
axis(2, at = seq_len(nrow(cm1)) -0.5,
labels = rev(rownames(cm1)), tick = FALSE, las = 1, cex.axis = 1)
################################################################################
# Fit PLS_DA model all wet
################################################################################
#data
spec_all1 = readRDS("Clean-up/Vector_normalized/vn_all_w.rds")
spec_all = spec_all1[!meta(spec_all1)$GenePop_ID == "NaN",]
names(spec_all) = meta(spec_all)$GenePop_ID
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
spec_mat = spec_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
#determine number of components to use
plsda.fit = plsda(spec_mat, resp, ncomp = 30)
perf.plsda = perf(plsda.fit, validation = "Mfold", folds = 5,
progressBar = TRUE, auc = TRUE, nrepeat = 50)
plot(perf.plsda, col = color.mixo(1:3), sd = TRUE,
legend.position = "horizontal")
set.seed(25)
samp <- sample(1:3, nrow(spec_mat), replace = TRUE)
# 1/3 of the data will compose the test set
test <- which(samp == 1)
# rest will compose the training set
train <- setdiff(1:nrow(spec_mat), test)
## For PLS-DA, train the model
plsda.train <- plsda(spec_mat[train, ], resp[train], ncomp = 19)
# then predict
test.predict <- predict(plsda.train, spec_mat[test, ], dist = "max.dist")
# store prediction for the 4th component
prediction <- test.predict$class$max.dist[,19]
# calculate the error rate of the model
confusion.mat = get.confusion_matrix(truth = resp[test], predicted = prediction)
cm1 = as.data.frame(confusion.mat)
get.BER(confusion.mat)
#plot
par(mar = c(2, 4, 3, 4), oma = c(2, 4, 3, 2))
color2D.matplot(cm1,
show.values = TRUE,
axes = FALSE,
xlab = "",
ylab = "",
vcex = 2,
vcol = "black",
extremes = c("white", "deepskyblue3"))
axis(3, at = seq_len(ncol(cm1)) - 0.5,
labels = names(cm1), tick = FALSE, cex.axis = 1)
axis(2, at = seq_len(nrow(cm1)) -0.5,
labels = rev(rownames(cm1)), tick = FALSE, las = 1, cex.axis = 1)
