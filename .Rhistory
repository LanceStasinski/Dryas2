klower = kavg - ksd
khigher = kavg + ksd
plot(kavg, type = 'p', pch = 16, cex = .75, ylab = 'Kappa', xlab = 'Component',
xlim = c(0,40), main = 'Kappa for sp_loc')
lines(klower, lty = 2, col = 'red')
lines(khigher, lty = 2, col = 'red')
abline(v = 26, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
plot(kavg, type = 'p', pch = 16, cex = .75, ylab = 'Kappa', xlab = 'Component',
xlim = c(0,40), main = 'Kappa for sp_loc')
lines(klower, lty = 2, col = 'red')
lines(khigher, lty = 2, col = 'red')
abline(v = 26, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
plot(kavg, type = 'p', pch = 16, cex = .75, ylab = 'Kappa', xlab = 'Component',
xlim = c(0,40), main = 'Kappa for sp_loc')
lines(klower, lty = 2, col = 'red')
lines(khigher, lty = 2, col = 'red')
abline(v = 37, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
a1 = as.matrix(plsFit1$results$Accuracy)
a2 = as.matrix(plsFit2$results$Accuracy)
a3 = as.matrix(plsFit3$results$Accuracy)
a4 = as.matrix(plsFit4$results$Accuracy)
a5 = as.matrix(plsFit5$results$Accuracy)
a6 = as.matrix(plsFit6$results$Accuracy)
a7 = as.matrix(plsFit7$results$Accuracy)
a8 = as.matrix(plsFit8$results$Accuracy)
a9 = as.matrix(plsFit9$results$Accuracy)
a10 = as.matrix(plsFit10$results$Accuracy)
a.total = Reduce(cbind, list(a1,a2,a3,a4,a5,a6,a7,a8,a9,a10))
a.avg = as.matrix(rowMeans(a.total))
a.sd = as.matrix(rowSds(a.total))
alower = a.avg - a.sd
ahigher = a.avg + a.sd
plot(a.avg, type = 'p', pch = 16, cex = .75, ylab = 'Accuracy', xlab = 'Component',
xlim = c(0,40), main = 'Accuracy for sp_loc')
lines(alower, lty = 2, col = 'red')
lines(ahigher, lty = 2, col = 'red')
abline(v = 37, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
plot(a.avg, type = 'p', pch = 16, cex = .75, ylab = 'Accuracy', xlab = 'Component',
xlim = c(0,60), main = 'Accuracy for sp_loc')
lines(alower, lty = 2, col = 'red')
lines(ahigher, lty = 2, col = 'red')
abline(v = 37, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
plot(a.avg, type = 'p', pch = 16, cex = .75, ylab = 'Accuracy', xlab = 'Component',
xlim = c(0,40), main = 'Accuracy for sp_loc')
lines(alower, lty = 2, col = 'red')
lines(ahigher, lty = 2, col = 'red')
abline(v = 37, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
################################################################################
# Fit PLS_DA model all dry
################################################################################
#data
spec_all = readRDS("Clean-up/Clean_spectra/clean_all.rds")
spec_all = spec_all[!meta(spec_all)$sp_loc == "NaN",]
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
spec_mat = spec_mat_s
#combine relavant meta data to matrix
spec_df = as.data.frame(spec_mat)
spec_df = cbind(spec_df, spec_all.df$sp_loc)
colnames(spec_df)[colnames(spec_df) == "spec_all.df$sp_loc"] <- "sp_loc"
unique(meta(spec_all)$sp_loc)
setwd("C:/Users/istas/OneDrive/Documents/Dryas Research/Dryas 2.0")
################################################################################
# Fit PLS_DA model all dry
################################################################################
#data
spec_all = readRDS("Clean-up/Clean_spectra/clean_all.rds")
spec_all = spec_all[!meta(spec_all)$sp_loc == "NaN",]
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
spec_mat = spec_mat_s
#combine relavant meta data to matrix
spec_df = as.data.frame(spec_mat)
spec_df = cbind(spec_df, spec_all.df$sp_loc)
colnames(spec_df)[colnames(spec_df) == "spec_all.df$sp_loc"] <- "sp_loc"
#Partition Data
for(i in 1:10){
set.seed(i)
inTrain <- caret::createDataPartition(
y = spec_df$sp_loc,
p = .8,
list = FALSE
)
training <- spec_df[inTrain,]
testing <- spec_df[-inTrain,]
#tune model
ctrl <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 3)
plsFit <- train(
sp_loc ~ .,
data = training,
method = "pls",
preProc = c("center", "scale"),
trControl = ctrl,
tuneLength = 37)
assign(paste0('plsFit', i), plsFit)
loadings = plsFit$finalModel$loadings
loadings.m = as.matrix(loadings)
class(loadings.m) <- 'matrix'
assign(paste0('lm',i), loadings.m)
comp1 = loadings.m[,1]
assign(paste0('comp1_',i), comp1)
comp2 = loadings.m[,2]
assign(paste0('comp2_',i), comp2)
comp3 = loadings.m[,3]
assign(paste0('comp3_',i), comp3)
#test model
plsClasses <- predict(plsFit, newdata = testing)
#Confusion matrices
cm = confusionMatrix(data = plsClasses, testing$sp_loc)
acc = cm$overall[1]
assign(paste0('acc',i), acc)
cm.m = as.matrix(cm)
assign(paste0("cm", i), cm.m)
}
acc = c(acc1, acc2, acc3, acc4, acc5, acc6, acc7, acc8, acc9, acc10)
mean.acc = mean(acc)
sd.acc = sd(acc)
mean.acc
sd.acc
cm.total = (cm1 + cm2 + cm3 + cm4 + cm5 + cm6 + cm7 + cm8+ cm9 + cm10)/10
cm.total = t(cm.total)
write.csv(cm.total, "Figures/raw confusion matrices/sp_loc_10it_20_37c")
cm.total = as.data.frame(cm.total)
cm.total = cm.total %>% replace_with_na_all(condition = ~.x == 0)
cm.total = as.matrix(cm.total)
rownames(cm.total) <- c('DA_es', 'DA_es', 'DA_wdb', 'DO_bg', 'DO_es', 'DO_mdb',
'DO_tm', 'DO_wda', 'DO_wdb', 'DX_es', 'DX_tm', 'DX_wdb')
write.csv(cm.total, "Figures/raw confusion matrices/sp_loc_test.csv")
cm.total = read.csv("Figures/raw confusion matrices/sp_loc_test.csv", stringsAsFactors = F)
row.names(cm.total) <- cm.total[,1]
cm.total = cm.total[,-1]
cm.total = as.matrix(cm.total)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 1, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 3.5, line = 2)
cm.total = read.csv("Figures/raw confusion matrices/sp_loc_test.csv", stringsAsFactors = F)
View(cm.total)
row.names(cm.total) <- cm.total[,1]
rownames(cm.total) <- cm.total[,1]
rownames(cm.total) <- c('DA_es', 'DA_es', 'DA_wdb', 'DO_bg', 'DO_es', 'DO_mdb',
'DO_tm', 'DO_wda', 'DO_wdb', 'DX_es', 'DX_tm', 'DX_wdb')
cm.total1 = read.csv("Figures/raw confusion matrices/sp_loc_test.csv", stringsAsFactors = F)
rownames(cm.total1) <- c('DA_es', 'DA_es', 'DA_wdb', 'DO_bg', 'DO_es', 'DO_mdb',
'DO_tm', 'DO_wda', 'DO_wdb', 'DX_es', 'DX_tm', 'DX_wdb')
cm.total = read.csv("Figures/raw confusion matrices/sp_loc_test.csv", stringsAsFactors = F)
rownames(cm.total) <- c('DA_es', 'DA_es', 'DA_wdb', 'DO_bg', 'DO_es', 'DO_mdb',
'DO_tm', 'DO_wda', 'DO_wdb', 'DX_es', 'DX_tm', 'DX_wdb')
View(cm.total)
cm.total = read.csv("Figures/raw confusion matrices/sp_loc_test.csv", stringsAsFactors = F)
setwd("C:/Users/istas/OneDrive/Documents/Dryas Research/Dryas 2.0")
library(spectrolab)
library(caret)
library(mlbench)
library(corrplot)
library(matrixStats)
library(naniar)
cm.total = read.csv("Figures/raw confusion matrices/sp_loc_test.csv", stringsAsFactors = F)
View(cm.total)
rownames(cm.total) <- cm.total[,1]
?read.csv
cm.total = as.matrix(cm.total)
View(cm.total)
rownames(cm.total) <- cm.total[,1]
View(cm.total)
cm.total = cm.total[,-1]
View(cm.total)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 1, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 6, line = 2)
View(cm.total)
cm.total = as.integer(cm.total)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 1, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 6, line = 2)
cm.total = as.matrix(cm.total)
View(cm.total)
cm.total = read.csv("Figures/raw confusion matrices/sp_loc_test.csv", stringsAsFactors = F)
View(cm.total)
cm.total = as.matrix(cm.total)
rownames(cm.total) <- cm.total[,1]
View(cm.total)
cm.total = cm.total[,-1]
cm.total = as.numeric(cm.total)
cm.total = read.csv("Figures/raw confusion matrices/sp_loc_test.csv", stringsAsFactors = T)
cm.total = as.matrix(cm.total)
rownames(cm.total) <- cm.total[,1]
cm.total = cm.total[,-1]
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 1, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 6, line = 2)
cm.total = mapply(cm.total, FUN = as.numeric)
cm.total = matrix(data = cm.total, ncol = 12, nrow = 12)
View(cm.total)
rownames(cm.total) <- c('DA_es', 'DA_mdb', 'DA_wdb', 'DO_bg', 'DO_es', 'DO_tm',
'DO_mdb', 'DO_wda', 'DO_wdb', 'DX_es', 'DX_tm', 'DX_wdb')
colnames(cm.total) <- c('DA_es', 'DA_mdb', 'DA_wdb', 'DO_bg', 'DO_es', 'DO_tm',
'DO_mdb', 'DO_wda', 'DO_wdb', 'DX_es', 'DX_tm', 'DX_wdb')
View(cm.total)
rownames(cm.total) <- c('DA_es', 'DA_tm', 'DA_wdb', 'DO_bg', 'DO_es', 'DO_tm',
'DO_mdb', 'DO_wda', 'DO_wdb', 'DX_es', 'DX_tm', 'DX_wdb')
colnames(cm.total) <- c('DA_es', 'DA_tm', 'DA_wdb', 'DO_bg', 'DO_es', 'DO_tm',
'DO_mdb', 'DO_wda', 'DO_wdb', 'DX_es', 'DX_tm', 'DX_wdb')
View(cm.total)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 1, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 6, line = 2)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 1, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 6, line = 2)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 0, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 6.5, line = 4)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 3, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 6.5, line = 5)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 90, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 3, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 6.5, line = 5)
setwd("C:/Users/istas/OneDrive/Documents/Dryas Research/Dryas 2.0")
################################################################################
# Fit PLS_DA model all dry
################################################################################
#data
spec_all = readRDS("Clean-up/Clean_spectra/clean_all.rds")
unique(meta(spec_all)$Location)
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
spec_mat = spec_mat_s
#combine relavant meta data to matrix
spec_df = as.data.frame(spec_mat)
spec_df = cbind(spec_df, spec_all.df$Location)
colnames(spec_df)[colnames(spec_df) == "spec_all.df$Location"] <- "Location"
#Partition Data
for(i in 1:10){
set.seed(i)
inTrain <- caret::createDataPartition(
y = spec_df$Location,
p = .8,
list = FALSE
)
training <- spec_df[inTrain,]
testing <- spec_df[-inTrain,]
#tune model
ctrl <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 3)
plsFit <- train(
Location ~ .,
data = training,
method = "pls",
preProc = c("center", "scale"),
trControl = ctrl,
tuneLength = 60)
assign(paste0('plsFit', i), plsFit)
loadings = plsFit$finalModel$loadings
loadings.m = as.matrix(loadings)
class(loadings.m) <- 'matrix'
assign(paste0('lm',i), loadings.m)
comp1 = loadings.m[,1]
assign(paste0('comp1_',i), comp1)
comp2 = loadings.m[,2]
assign(paste0('comp2_',i), comp2)
comp3 = loadings.m[,3]
assign(paste0('comp3_',i), comp3)
#test model
plsClasses <- predict(plsFit, newdata = testing)
#Confusion matrices
cm = confusionMatrix(data = plsClasses, testing$Location)
acc = cm$overall[1]
assign(paste0('acc',i), acc)
cm.m = as.matrix(cm)
assign(paste0("cm", i), cm.m)
}
k1 = as.matrix(plsFit1$results$Kappa)
k2 = as.matrix(plsFit2$results$Kappa)
k3 = as.matrix(plsFit3$results$Kappa)
k4 = as.matrix(plsFit4$results$Kappa)
k5 = as.matrix(plsFit5$results$Kappa)
k6 = as.matrix(plsFit6$results$Kappa)
k7 = as.matrix(plsFit7$results$Kappa)
k8 = as.matrix(plsFit8$results$Kappa)
k9 = as.matrix(plsFit9$results$Kappa)
k10 = as.matrix(plsFit10$results$Kappa)
k.total = Reduce(cbind, list(k1,k2,k3,k4,k5,k6,k7,k8,k9,k10))
kavg = as.matrix(rowMeans(k.total))
ksd = as.matrix(rowSds(k.total))
klower = kavg - ksd
khigher = kavg + ksd
plot(kavg, type = 'p', pch = 16, cex = .75, ylab = 'Kappa', xlab = 'Component',
xlim = c(0,40), main = 'Kappa for Location')
lines(klower, lty = 2, col = 'red')
lines(khigher, lty = 2, col = 'red')
abline(v = 37, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
plot(kavg, type = 'p', pch = 16, cex = .75, ylab = 'Kappa', xlab = 'Component',
xlim = c(0,60), main = 'Kappa for Location')
lines(klower, lty = 2, col = 'red')
lines(khigher, lty = 2, col = 'red')
abline(v = 37, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
plot(kavg, type = 'p', pch = 16, cex = .75, ylab = 'Kappa', xlab = 'Component',
xlim = c(0,40), main = 'Kappa for Location')
lines(klower, lty = 2, col = 'red')
lines(khigher, lty = 2, col = 'red')
abline(v = 34, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
plot(kavg, type = 'p', pch = 16, cex = .75, ylab = 'Kappa', xlab = 'Component',
xlim = c(0,40), main = 'Kappa for Location')
lines(klower, lty = 2, col = 'red')
lines(khigher, lty = 2, col = 'red')
abline(v = 35, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
a1 = as.matrix(plsFit1$results$Accuracy)
a2 = as.matrix(plsFit2$results$Accuracy)
a3 = as.matrix(plsFit3$results$Accuracy)
a4 = as.matrix(plsFit4$results$Accuracy)
a5 = as.matrix(plsFit5$results$Accuracy)
a6 = as.matrix(plsFit6$results$Accuracy)
a7 = as.matrix(plsFit7$results$Accuracy)
a8 = as.matrix(plsFit8$results$Accuracy)
a9 = as.matrix(plsFit9$results$Accuracy)
a10 = as.matrix(plsFit10$results$Accuracy)
a.total = Reduce(cbind, list(a1,a2,a3,a4,a5,a6,a7,a8,a9,a10))
a.avg = as.matrix(rowMeans(a.total))
a.sd = as.matrix(rowSds(a.total))
alower = a.avg - a.sd
ahigher = a.avg + a.sd
plot(a.avg, type = 'p', pch = 16, cex = .75, ylab = 'Accuracy', xlab = 'Component',
xlim = c(0,40), main = 'Accuracy for Location')
lines(alower, lty = 2, col = 'red')
lines(ahigher, lty = 2, col = 'red')
abline(v = 35, col = 'blue')
legend('bottomright', legend = c('Mean', 'Standard deviation', 'Best component'),
pch = c(16, NA, NA), lty = c(NA, 2, 1), col = c('black', 'red', 'blue'))
#data
spec_all = readRDS("Clean-up/Clean_spectra/clean_all.rds")
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
spec_mat = spec_mat_s
#combine relavant meta data to matrix
spec_df = as.data.frame(spec_mat)
spec_df = cbind(spec_df, spec_all.df$Location)
colnames(spec_df)[colnames(spec_df) == "spec_all.df$Location"] <- "Location"
#Partition Data
for(i in 1:10){
set.seed(i)
inTrain <- caret::createDataPartition(
y = spec_df$Location,
p = .8,
list = FALSE
)
training <- spec_df[inTrain,]
testing <- spec_df[-inTrain,]
#tune model
ctrl <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 3)
plsFit <- train(
Location ~ .,
data = training,
method = "pls",
preProc = c("center", "scale"),
trControl = ctrl,
tuneLength = 35)
assign(paste0('plsFit', i), plsFit)
loadings = plsFit$finalModel$loadings
loadings.m = as.matrix(loadings)
class(loadings.m) <- 'matrix'
assign(paste0('lm',i), loadings.m)
comp1 = loadings.m[,1]
assign(paste0('comp1_',i), comp1)
comp2 = loadings.m[,2]
assign(paste0('comp2_',i), comp2)
comp3 = loadings.m[,3]
assign(paste0('comp3_',i), comp3)
#test model
plsClasses <- predict(plsFit, newdata = testing)
#Confusion matrices
cm = confusionMatrix(data = plsClasses, testing$Location)
acc = cm$overall[1]
assign(paste0('acc',i), acc)
cm.m = as.matrix(cm)
assign(paste0("cm", i), cm.m)
}
acc = c(acc1, acc2, acc3, acc4, acc5, acc6, acc7, acc8, acc9, acc10)
mean.acc = mean(acc)
sd.acc = sd(acc)
mean.acc
sd.acc
cm.total = (cm1 + cm2 + cm3 + cm4 + cm5 + cm6 + cm7 + cm8+ cm9 + cm10)/10
cm.total = t(cm.total)
write.csv(cm.total, "Figures/raw confusion matrices/Location_10it_20_35c")
cm.total = as.data.frame(cm.total)
cm.total = cm.total %>% replace_with_na_all(condition = ~.x == 0)
cm.total = as.matrix(cm.total)
rownames(cm.total) <- c('Bison Gulch', 'Eagle Summit', 'Murphy Dome B',
'Twelve Mile', 'Wickersham Dome A', 'Wickersham Dome B')
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 90, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 3, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 6.5, line = 5)
colnames(cm.total) <- c('BG', 'ES', 'MDB', 'TM', 'WDA', 'WDB')
View(cm.total)
cm.total = (cm1 + cm2 + cm3 + cm4 + cm5 + cm6 + cm7 + cm8+ cm9 + cm10)/10
cm.total = t(cm.total)
write.csv(cm.total, "Figures/raw confusion matrices/Location_10it_20_35c")
cm.total = as.data.frame(cm.total)
cm.total = cm.total %>% replace_with_na_all(condition = ~.x == 0)
cm.total = as.matrix(cm.total)
rownames(cm.total) <- c('BG', 'ES', 'MDB', 'TM', 'WDA', 'WDB')
colnames(cm.total) <- c('BG', 'ES', 'MDB', 'TM', 'WDA', 'WDB')
View(cm.total)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 90, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 3, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 6.5, line = 5)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = -3, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 3.5, line = 5)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = -1, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 3.5, line = 4)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
corrplot(cm.total, is.corr = F, method = 'color', addCoef.col = 'darkorange2',
tl.srt = 0, tl.offset = 1.5, number.digits = 2, tl.cex = .75,
tl.col = 'black', cl.pos = 'n', na.label = 'square',
na.label.col = 'white', addgrid.col = 'grey')
mtext("Reference", side = 2, line = 0, cex = 1.5)
mtext("Prediction", side = 3, cex = 1.5, at = 3.5, line = 4)
