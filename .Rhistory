names(spec_all) = meta(spec_all)$Species
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
#add location as variable
spec_LMA_mat_s = cbind(as.factor(spec_all.df$LMA), spec_mat_s)
spec_mat   = spec_LMA_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
#determine components to use
plsda.fit = plsda(spec_mat, resp, ncomp = 40)
perf.plsda = perf(plsda.fit, validation = "Mfold", folds = 5,
progressBar = TRUE, auc = TRUE, nrepeat = 10)
plot(perf.plsda, col = color.mixo(1:3), sd = TRUE,
legend.position = "horizontal")
set.seed(26)
samp <- sample(1:3, nrow(spec_mat), replace = TRUE)
# 1/3 of the data will compose the test set
test <- which(samp == 1)
# rest will compose the training set
train <- setdiff(1:nrow(spec_mat), test)
## For PLS-DA, train the model
plsda.train <- plsda(spec_mat[train, ], resp[train], ncomp = 40)
# then predict
test.predict <- predict(plsda.train, spec_mat[test, ], dist = "max.dist")
# store prediction for the 4th component
prediction <- test.predict$class$max.dist[,40]
# calculate the error rate of the model
confusion.mat = get.confusion_matrix(truth = resp[test], predicted = prediction)
cm1 = as.data.frame(confusion.mat)
get.BER(confusion.mat)
#plot
par(mar = c(2, 4, 3, 4), oma = c(2, 4, 3, 2))
color2D.matplot(cm1,
show.values = TRUE,
axes = FALSE,
xlab = "",
ylab = "",
vcex = 2,
vcol = "black",
extremes = c("white", "deepskyblue3"))
axis(3, at = seq_len(ncol(cm1)) - 0.5,
labels = names(cm1), tick = FALSE, cex.axis = 1)
axis(2, at = seq_len(nrow(cm1)) -0.5,
labels = rev(rownames(cm1)), tick = FALSE, las = 1, cex.axis = 1)
################################################################################
# Fit PLS_DA model all
################################################################################
#data
spec = readRDS("Clean-up/Vector_normalized/vn_all_w.rds")
unique(meta(spec))$Species)
unique(meta(spec)$Species)
spec_nohyb = spec[!meta(spec)$Species == "hybrid",]
unique(meta(spec_nohyb)$Species)
spec = readRDS("Clean-up/Vector_normalized/vn_all_w.rds")
spec_nohyb = spec[!meta(spec)$Species == "hybrid",]
names(spec_all) = meta(spec_all)$Species
spec_all = spec_nohyb
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
spec_mat = spec_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
#determine number of components to use
plsda.fit = plsda(spec_mat, resp, ncomp = 40)
perf.plsda = perf(plsda.fit, validation = "Mfold", folds = 5,
progressBar = TRUE, auc = TRUE, nrepeat = 10)
plot(perf.plsda, col = color.mixo(1:3), sd = TRUE,
legend.position = "horizontal")
spec = readRDS("Clean-up/Vector_normalized/vn_all_w.rds")
spec_nohyb = spec[!meta(spec)$Species == "hybrid",]
spec_all = spec_nohyb
names(spec_all) = meta(spec_all)$Species
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
spec_mat = spec_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
#determine number of components to use
plsda.fit = plsda(spec_mat, resp, ncomp = 40)
perf.plsda = perf(plsda.fit, validation = "Mfold", folds = 5,
progressBar = TRUE, auc = TRUE, nrepeat = 10)
plot(perf.plsda, col = color.mixo(1:3), sd = TRUE,
legend.position = "horizontal")
#Run PLSDA
set.seed(25)
samp <- sample(1:3, nrow(spec_mat), replace = TRUE)
# 1/3 of the data will compose the test set
test <- which(samp == 1)
# rest will compose the training set
train <- setdiff(1:nrow(spec_mat), test)
## For PLS-DA, train the model
plsda.train <- plsda(spec_mat[train, ], resp[train], ncomp = 32)
# then predict
test.predict <- predict(plsda.train, spec_mat[test, ], dist = "max.dist")
# store prediction for the 4th component
prediction <- test.predict$class$max.dist[,32]
# calculate the error rate of the model
confusion.mat = get.confusion_matrix(truth = resp[test], predicted = prediction)
cm1 = as.data.frame(confusion.mat)
get.BER(confusion.mat)
#plot
par(mar = c(2, 4, 3, 4), oma = c(2, 4, 3, 2))
color2D.matplot(cm1,
show.values = TRUE,
axes = FALSE,
xlab = "",
ylab = "",
vcex = 2,
vcol = "black",
extremes = c("white", "deepskyblue3"))
axis(3, at = seq_len(ncol(cm1)) - 0.5,
labels = names(cm1), tick = FALSE, cex.axis = 1)
axis(2, at = seq_len(nrow(cm1)) -0.5,
labels = rev(rownames(cm1)), tick = FALSE, las = 1, cex.axis = 1)
spec = readRDS("Clean-up/Vector_normalized/vn_all_w.rds")
spec_nohyb = spec[!meta(spec)$Species == "hybrid",]
spec_all = spec_nohyb
names(spec_all) = meta(spec_all)$Species
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
#add location as variable
spec_loc_mat_s = cbind(as.factor(spec_all.df$Location), spec_mat_s)
spec_mat   = spec_loc_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
#determine number of components to use
plsda.fit = plsda(spec_mat, resp, ncomp = 40)
perf.plsda = perf(plsda.fit, validation = "Mfold", folds = 5,
progressBar = TRUE, auc = TRUE, nrepeat = 10)
plot(perf.plsda, col = color.mixo(1:3), sd = TRUE,
legend.position = "horizontal")
set.seed(25)
samp <- sample(1:3, nrow(spec_mat), replace = TRUE)
# 1/3 of the data will compose the test set
test <- which(samp == 1)
# rest will compose the training set
train <- setdiff(1:nrow(spec_mat), test)
## For PLS-DA, train the model
plsda.train <- plsda(spec_mat[train, ], resp[train], ncomp = 32)
# then predict
test.predict <- predict(plsda.train, spec_mat[test, ], dist = "max.dist")
# store prediction for the 4th component
prediction <- test.predict$class$max.dist[,32]
# calculate the error rate of the model
confusion.mat = get.confusion_matrix(truth = resp[test], predicted = prediction)
cm1 = as.data.frame(confusion.mat)
get.BER(confusion.mat)
#plot
par(mar = c(2, 4, 3, 4), oma = c(2, 4, 3, 2))
color2D.matplot(cm1,
show.values = TRUE,
axes = FALSE,
xlab = "",
ylab = "",
vcex = 2,
vcol = "black",
extremes = c("white", "deepskyblue3"))
axis(3, at = seq_len(ncol(cm1)) - 0.5,
labels = names(cm1), tick = FALSE, cex.axis = 1)
axis(2, at = seq_len(nrow(cm1)) -0.5,
labels = rev(rownames(cm1)), tick = FALSE, las = 1, cex.axis = 1)
spec = readRDS("Clean-up/Vector_normalized/vn_all_w.rds")
spec_nohyb = spec[!meta(spec)$Species == "hybrid",]
spec_all = spec_nohyb
names(spec_all) = meta(spec_all)$Species
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
#add location as variable
spec_loc_mat_s = cbind(as.factor(spec_all.df$Location), spec_mat_s)
spec_mat   = spec_loc_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
spec_mat = spec_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
#determine number of components to use
plsda.fit = plsda(spec_mat, resp, ncomp = 40)
perf.plsda = perf(plsda.fit, validation = "Mfold", folds = 5,
progressBar = TRUE, auc = TRUE, nrepeat = 10)
plot(perf.plsda, col = color.mixo(1:3), sd = TRUE,
legend.position = "horizontal")
set.seed(25)
samp <- sample(1:3, nrow(spec_mat), replace = TRUE)
# 1/3 of the data will compose the test set
test <- which(samp == 1)
# rest will compose the training set
train <- setdiff(1:nrow(spec_mat), test)
## For PLS-DA, train the model
plsda.train <- plsda(spec_mat[train, ], resp[train], ncomp = 31)
# then predict
test.predict <- predict(plsda.train, spec_mat[test, ], dist = "max.dist")
# store prediction for the 4th component
prediction <- test.predict$class$max.dist[,31]
# calculate the error rate of the model
confusion.mat = get.confusion_matrix(truth = resp[test], predicted = prediction)
cm1 = as.data.frame(confusion.mat)
get.BER(confusion.mat)
#plot
par(mar = c(2, 4, 3, 4), oma = c(2, 4, 3, 2))
color2D.matplot(cm1,
show.values = TRUE,
axes = FALSE,
xlab = "",
ylab = "",
vcex = 2,
vcol = "black",
extremes = c("white", "deepskyblue3"))
axis(3, at = seq_len(ncol(cm1)) - 0.5,
labels = names(cm1), tick = FALSE, cex.axis = 1)
axis(2, at = seq_len(nrow(cm1)) -0.5,
labels = rev(rownames(cm1)), tick = FALSE, las = 1, cex.axis = 1)
spec = readRDS("Clean-up/Vector_normalized/vn_all_w.rds")
spec_nohyb = spec[!meta(spec)$Species == "hybrid",]
spec_all = spec_nohyb
names(spec_all) = meta(spec_all)$Species
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
#add LMA as variable
spec_LMA_mat_s = cbind(as.factor(spec_all.df$LMA), spec_mat_s)
spec_mat   = spec_LMA_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
spec_mat = spec_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
#determine number of components to use
plsda.fit = plsda(spec_mat, resp, ncomp = 40)
perf.plsda = perf(plsda.fit, validation = "Mfold", folds = 5,
progressBar = TRUE, auc = TRUE, nrepeat = 10)
plot(perf.plsda, col = color.mixo(1:3), sd = TRUE,
legend.position = "horizontal")
#Run PLSDA
set.seed(25)
samp <- sample(1:3, nrow(spec_mat), replace = TRUE)
# 1/3 of the data will compose the test set
test <- which(samp == 1)
# rest will compose the training set
train <- setdiff(1:nrow(spec_mat), test)
## For PLS-DA, train the model
plsda.train <- plsda(spec_mat[train, ], resp[train], ncomp = 32)
# then predict
test.predict <- predict(plsda.train, spec_mat[test, ], dist = "max.dist")
# store prediction for the 4th component
prediction <- test.predict$class$max.dist[,32]
# calculate the error rate of the model
confusion.mat = get.confusion_matrix(truth = resp[test], predicted = prediction)
cm1 = as.data.frame(confusion.mat)
get.BER(confusion.mat)
#plot
par(mar = c(2, 4, 3, 4), oma = c(2, 4, 3, 2))
color2D.matplot(cm1,
show.values = TRUE,
axes = FALSE,
xlab = "",
ylab = "",
vcex = 2,
vcol = "black",
extremes = c("white", "deepskyblue3"))
axis(3, at = seq_len(ncol(cm1)) - 0.5,
labels = names(cm1), tick = FALSE, cex.axis = 1)
axis(2, at = seq_len(nrow(cm1)) -0.5,
labels = rev(rownames(cm1)), tick = FALSE, las = 1, cex.axis = 1)
#data
spec_all = readRDS("Clean-up/Vector_normalized/vn_all_w.rds")
names(spec_all) = meta(spec_all)$Location
spec_all.m = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#Resample by every 10 nm
spec_small = resample(spec_all, seq(400, 2400, by = 10))
spec_mat_s = as.matrix(spec_small)
spec_mat = spec_mat_s
resp = rownames(spec_mat)
rownames(spec_mat) = seq(nrow(spec_mat))
set.seed(25)
samp <- sample(1:3, nrow(spec_mat), replace = TRUE)
# 1/3 of the data will compose the test set
test <- which(samp == 1)
# rest will compose the training set
train <- setdiff(1:nrow(spec_mat), test)
## For PLS-DA, train the model
plsda.train <- plsda(spec_mat[train, ], resp[train], ncomp = 9)
# then predict
test.predict <- predict(plsda.train, spec_mat[test, ], dist = "max.dist")
# store prediction for the 4th component
prediction <- test.predict$class$max.dist[,9]
# calculate the error rate of the model
confusion.mat = get.confusion_matrix(truth = resp[test], predicted = prediction)
cm1 = as.data.frame(confusion.mat)
get.BER(confusion.mat)
#plot
par(mar = c(2, 5, 3, 4), oma = c(2, 4, 3, 2))
color2D.matplot(cm1,
show.values = TRUE,
axes = FALSE,
xlab = "",
ylab = "",
vcex = 2,
vcol = "black",
extremes = c("white", "deepskyblue3"))
axis(3, at = seq_len(ncol(cm1)) - 0.5,
labels = names(cm1), tick = FALSE, cex.axis = 1)
axis(2, at = seq_len(nrow(cm1)) -0.5,
labels = rev(rownames(cm1)), tick = FALSE, las = 1, cex.axis = 1)
set.seed(25)
samp <- sample(1:3, nrow(spec_mat), replace = F)
# 1/3 of the data will compose the test set
test <- which(samp == 1)
# rest will compose the training set
train <- setdiff(1:nrow(spec_mat), test)
## For PLS-DA, train the model
plsda.train <- plsda(spec_mat[train, ], resp[train], ncomp = 9)
# then predict
test.predict <- predict(plsda.train, spec_mat[test, ], dist = "max.dist")
# store prediction for the 4th component
prediction <- test.predict$class$max.dist[,9]
# calculate the error rate of the model
confusion.mat = get.confusion_matrix(truth = resp[test], predicted = prediction)
cm1 = as.data.frame(confusion.mat)
get.BER(confusion.mat)
#plot
par(mar = c(2, 5, 3, 4), oma = c(2, 4, 3, 2))
color2D.matplot(cm1,
show.values = TRUE,
axes = FALSE,
xlab = "",
ylab = "",
vcex = 2,
vcol = "black",
extremes = c("white", "deepskyblue3"))
axis(3, at = seq_len(ncol(cm1)) - 0.5,
labels = names(cm1), tick = FALSE, cex.axis = 1)
axis(2, at = seq_len(nrow(cm1)) -0.5,
labels = rev(rownames(cm1)), tick = FALSE, las = 1, cex.axis = 1)
library(spectrolab)
setwd("C:/Users/istas/OneDrive/Documents/Dryas Research/Dryas 2.0")
spec_all = readRDS("Clean-up/Vector_normalized/vn_all.rds")
names(spec_all) <- meta(spec_all)$Species
plot_interactive(spec_all)
setwd("C:/Users/istas/OneDrive/Documents/Dryas Research/Dryas 2.0")
spec_all = readRDS("Clean-up/Vector_normalized/all_vn.rds")
names(spec_all) <- meta(spec_all)$Species
plot_interactive(spec_all)
setwd("C:/Users/istas/OneDrive/Documents/Dryas Research/Dryas 2.0")
spec_all = readRDS("Clean-up/Vector_normalized/all_vn.rds")
s9 = spec_all[9,]
s9
meta(s9)
plot_interactive(spec_all)
s481 = spec_all[481,]
meta(s481)
plot_interactive(spec_all)
f = function(spec, specnumber){
meta(spec[specnumber,])
}
#low
s9 = f(spec_all, 9) #ala, tm
#low
f(spec_all, 9) #ala, tm
plot_interactive(spec_all)
quantile(specall, probs = .25)
quantile(spec_all, probs = .25)
speclow = spec_all[<quantile(spec_all, probs =.25),]
speclow = spec_all[quantile(spec_all, probs =c(0,.25),]
speclow = spec_all[spec_all<quantile(spec_all, probs =.25),]
plot_interactive(spec_all)
l1 = f(spec_all, 9) #ala, tm
l2 = f(spec_all, 12)
l3 = f(spec_all, 10)
l4 = f(spec_all, 32)
l5 = f(spec_all, 51)
l6 = f(spec_all, 79)
l7 = f(spec_all, 82)
l8 = f(spec_all, 70)
l9 = f(spec_all, 39)
l10 = f(spec_all, 81)
low = meta(Reduce(combine, list(l1,l2,l3,l4,l5,l6,l7,l8,l9,l10)))
f = function(spec, specnumber){
spec[specnumber,]
}
#low
l1 = f(spec_all, 9) #ala, tm
l2 = f(spec_all, 12)
l3 = f(spec_all, 10)
l4 = f(spec_all, 32)
l5 = f(spec_all, 51)
l6 = f(spec_all, 79)
l7 = f(spec_all, 82)
l8 = f(spec_all, 70)
l9 = f(spec_all, 39)
l10 = f(spec_all, 81)
low = meta(Reduce(combine, list(l1,l2,l3,l4,l5,l6,l7,l8,l9,l10)))
low
m1 = f(spec_all, 583)
m2 = f(spec_all, 582)
m3 = f(spec_all, 89)
m4 = f(spec_all, 572)
m5 = f(spec_all, 575)
m6 = f(spec_all, 560)
m7 = f(spec_all, 97)
m8 = f(spec_all, 143)
m9 = f(spec_all, 95)
m10 = f(spec_all, 17)
medium = meta(Reduce(combine, list(m1,m2,m3,m4,m5,m6,m7,m8,m9,m10)))
medium
h1 = f(spec_all, 194)
h2 = f(spec_all, 195)
h3 = f(spec_all, 327)
h4 = f(spec_all, 297)
h5 = f(spec_all, 386)
h6 = f(spec_all, 494)
h7 = f(spec_all, 344)
h8 = f(spec_all, 205)
h9 = f(spec_all, 272)
h10 = f(spec_all, 319)
high = meta(Reduce(combine, list(h1, h2, h3, h4, h5, h6, h7, h8, h9, h10)))
high
plot_interactive(spec_all)
plot_interactive(spec_all[200:783,])
#low
l1 = f(spec_all, 9) #ala, tm
l2 = f(spec_all, 12) #ala, tm
l3 = f(spec_all, 10) #ala, tm
l4 = f(spec_all, 32)
l5 = f(spec_all, 51)
l6 = f(spec_all, 79)
l7 = f(spec_all, 82)
l8 = f(spec_all, 70)
l9 = f(spec_all, 39)
l10 = f(spec_all, 81)
l11 = f(spec_all, 663)
l12 = f(spec_all, 750)
l13 = f(spec_all, 743)
l14 = f(spec_all, 683)
l15 = f(spec_all, 651)
l16 = f(spec_all, 673)
l17 = f(spec_all, 707)
l18 = f(spec_all, 784)
l19 = f(spec_all, 744)
l20 = f(spec_all, 603)
low = meta(Reduce(combine, list(l1,l2,l3,l4,l5,l6,l7,l8,l9,l10,l12,l13,l14,l15,
l16,l17,l18,l19,l20)))
#all 8 ala and 2 hyb, all in tm
#medium
m1 = f(spec_all, 583)
m2 = f(spec_all, 582)
m3 = f(spec_all, 89)
m4 = f(spec_all, 572)
m5 = f(spec_all, 575)
m6 = f(spec_all, 560)
m7 = f(spec_all, 97)
m8 = f(spec_all, 143)
m9 = f(spec_all, 95)
m10 = f(spec_all, 17)
m11 = f(spec_all, 497)
m12 = f(spec_all, 722)
m13 = f(spec_all, 682)
m14 = f(spec_all, 619)
m15 = f(spec_all, 733)
m16 = f(spec_all, 662)
m17 = f(spec_all, 766)
m18 = f(spec_all, 489)
m19 = f(spec_all, 644)
m20 = f(spec_all, 367)
medium = meta(Reduce(combine, list(m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12,m13
m14,m15,m16,m17,m18,m19,m20)))
#6 oct, 3 hyb, 1 ala, tm and mdb
h1 = f(spec_all, 194)
h2 = f(spec_all, 195)
h3 = f(spec_all, 327)
h4 = f(spec_all, 297)
h5 = f(spec_all, 386)
h6 = f(spec_all, 494)
h7 = f(spec_all, 344)
h8 = f(spec_all, 205)
h9 = f(spec_all, 272)
h10 = f(spec_all, 319)
h11 = f(spec_all, 371)
h12 = f(spec_all, 372)
h13 = f(spec_all, 236)
h14 = f(spec_all, 384)
h15 = f(spec_all, 221)
h16 = f(spec_all, 230)
h17 = f(spec_all, 314)
h18 = f(spec_all, 302)
h19 = f(spec_all, 345)
h20 = f(spec_all, 262)
high = meta(Reduce(combine, list(h1, h2, h3, h4, h5, h6, h7, h8, h9, h10, h11,
h12, h13, h14, h15, h16, h17, h18, h19, h20)))
medium = meta(Reduce(combine, list(m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12,m13,
m14,m15,m16,m17,m18,m19,m20)))
low
medium
high
plot_interactive(spec_all[200:783,])
